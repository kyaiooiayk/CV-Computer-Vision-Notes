{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** Image augmentation\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MNIST dataset\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Create a grid of 3x3 images   \n",
    "for i in range(0, 9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_train[i], cmap=pyplot.get_cmap(\"gray\"))\n",
    "\n",
    "# Show the plots\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Standardization\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- It is also possible to standardise pixel values across the entire dataset. \n",
    "- This is called feature **standardisation** and mirrors the type of standardization often performed for each column in a tabular dataset.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "# convert from int to float\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    #for i in range(0, 9):\n",
    "    for i in range(0, 6):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap(\"gray\"))\n",
    "\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Running this example you can see that the eâ†µect on the actual images, seemingly darkening and lightening different digits.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZCA Whitening\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- You can see the same general structure in the images and how the outline of each digit has been highlighted. \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "# convert from int to float\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 6):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap(\"gray\"))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random rotation\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Sometimes images in your sample data may have varying and different rotations in the scene. \n",
    "- You can train your model to better handle rotations of images by artificially and randomly rotating images from your dataset during training.\n",
    "- Running the example, you can see that images have been rotated left and right up to a limit of 90 degrees. \n",
    "- This is **NOT** helpful on this problem because the MNIST digits have a normalized orientation, but this transform might be of help when learning from photographs where the objects may have different orientations.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "# convert from int to float\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=6):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 6):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap(\"gray\"))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Shifts\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Objects in your images may not be centered in the frame. \n",
    "- They may be offcenter in a variety of different ways.\n",
    "- You can train your deep learning network to expect and currently handle offcenter objects by artificially creating shifted versions of your training data\n",
    "- Running this example creates shifted versions of the digits. \n",
    "- Again, this is **NOT** required for MNIST as thehandwritten digits are already centered, but you can see how this might be useful on more complex problem domain.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "# convert from int to float\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# define data preparation\n",
    "shift = 0.2\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=6):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 6):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap(\"gray\"))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Flips\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Another augmentation to your image data that can improve performance on large and complex problems is to create random flips of images in your training data.  \n",
    "- Running this example you can see flipped digits. \n",
    "- Flipping digits in MNIST is **NOT** useful as they will alwayshave the correct left and right orientation, but this may be useful for problems with photographs of objects in a scene that can have a varied orientation\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "# convert from int to float\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# fit parameters from data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap(\"gray\"))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "    \n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
